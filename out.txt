--- Testing with 500 sentences ---
Data prepared with 500 sentences.
Train: 400 examples
Dev: 100 examples
⚠ To generate a more effective transformer-based config (GPU-only),
install the spacy-transformers package and re-run this command. The config
generated now does not use transformers.
ℹ Generated config template specific for your use case
- Language: fr
- Pipeline: ner
- Optimize for: efficiency
- Hardware: CPU
- Transformer: None
✔ Auto-filled config with all values
✔ Saved config
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
ℹ Saving to output directory: output_500
ℹ Using CPU

=========================== Initializing pipeline ===========================
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['tok2vec', 'ner']
ℹ Initial learn rate: 0.001
E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  ------------  --------  ------  ------  ------  ------
  0       0          0.00     56.70    0.00    0.00    0.00    0.00
  6     200        227.85   2582.54   90.45   90.91   90.00    0.90
 13     400         15.55     31.56   92.19   92.89   91.50    0.92
 22     600          6.77      3.54   89.72   89.95   89.50    0.90
 34     800         22.84      9.91   91.73   91.96   91.50    0.92
 47    1000         66.65     17.88   93.50   93.50   93.50    0.94
 64    1200        122.34     27.56   90.68   91.37   90.00    0.91
 85    1400         39.94      8.78   91.18   91.88   90.50    0.91
109    1600          0.01      0.01   89.39   90.31   88.50    0.89
140    1800        231.97     64.94   93.03   92.57   93.50    0.93
176    2000        673.41    174.84   95.74   95.98   95.50    0.96
220    2200         18.60      2.14   92.19   92.89   91.50    0.92
270    2400          0.00      0.00   92.93   93.88   92.00    0.93
320    2600          0.00      0.00   92.93   93.88   92.00    0.93
370    2800          0.00      0.00   92.93   93.88   92.00    0.93
420    3000          0.00      0.00   92.93   93.88   92.00    0.93
470    3200          0.00      0.00   92.93   93.88   92.00    0.93
520    3400          0.00      0.00   92.93   93.88   92.00    0.93
570    3600          0.00      0.00   92.93   93.88   92.00    0.93
✔ Saved pipeline to output directory
output_500/model-last

Results for 500 sentences:
ℹ Using CPU

================================== Results ==================================

TOK     100.00
NER P   95.98 
NER R   95.50 
NER F   95.74 
SPEED   22525 


=============================== NER (per type) ===============================

                     P       R       F
VILLE_ARRIVEE   100.00   94.00   96.91
VILLE_ORIGINE    92.38   97.00   94.63


--- Finished testing with 500 sentences ---

--- Testing with 1000 sentences ---
Data prepared with 1000 sentences.
Train: 800 examples
Dev: 200 examples
⚠ To generate a more effective transformer-based config (GPU-only),
install the spacy-transformers package and re-run this command. The config
generated now does not use transformers.
ℹ Generated config template specific for your use case
- Language: fr
- Pipeline: ner
- Optimize for: efficiency
- Hardware: CPU
- Transformer: None
✔ Auto-filled config with all values
✔ Saved config
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
✔ Created output directory: output_1000
ℹ Saving to output directory: output_1000
ℹ Using CPU

=========================== Initializing pipeline ===========================
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['tok2vec', 'ner']
ℹ Initial learn rate: 0.001
E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  ------------  --------  ------  ------  ------  ------
  0       0          0.00     60.90    0.00    0.00    0.00    0.00
  3     200        178.95   2953.74   95.89   95.53   96.25    0.96
  6     400        111.59    165.14   94.99   95.23   94.75    0.95
 11     600        180.07     84.70   96.36   96.73   96.00    0.96
 17     800        140.59     67.11   97.13   97.01   97.25    0.97
 24    1000         63.35     26.40   97.38   97.26   97.50    0.97
 32    1200         12.29      2.78   96.88   96.76   97.00    0.97
 42    1400          4.30      0.76   97.49   97.74   97.25    0.97
 55    1600         50.36      7.09   97.50   97.50   97.50    0.97
 70    1800        431.40     99.73   96.12   96.24   96.00    0.96
 89    2000         84.42     15.38   97.49   97.98   97.00    0.97
112    2200         65.81     12.24   95.99   96.23   95.75    0.96
139    2400        248.59     27.95   96.25   96.25   96.25    0.96
168    2600        233.51     35.48   96.87   96.99   96.75    0.97
196    2800        124.49     17.40   96.99   97.24   96.75    0.97
225    3000         91.31     11.01   97.75   97.75   97.75    0.98
254    3200        328.53     27.95   97.26   97.01   97.50    0.97
282    3400          0.00      0.00   97.13   97.01   97.25    0.97
311    3600          0.00      0.00   97.50   97.50   97.50    0.97
339    3800         19.39      3.52   97.38   97.26   97.50    0.97
368    4000       1760.16    128.93   97.75   97.75   97.75    0.98
396    4200       8822.35    930.37   97.63   97.51   97.75    0.98
425    4400         35.73      4.42   97.99   98.24   97.75    0.98
454    4600          0.00      0.00   98.25   98.49   98.00    0.98
482    4800          0.00      0.00   98.25   98.49   98.00    0.98
511    5000          0.00      0.00   98.25   98.49   98.00    0.98
539    5200         56.19      6.92   98.37   98.50   98.25    0.98
568    5400          6.24      1.06   97.99   98.24   97.75    0.98
596    5600         50.50      4.23   97.74   97.99   97.50    0.98
625    5800          0.01      0.00   97.99   98.24   97.75    0.98
654    6000         93.40      7.16   96.60   97.22   96.00    0.97
682    6200        227.81     15.56   97.37   97.73   97.00    0.97
711    6400          0.00      0.00   97.37   97.73   97.00    0.97
739    6600          9.76      3.14   97.62   97.98   97.25    0.98
768    6800          0.00      0.00   97.62   97.98   97.25    0.98
✔ Saved pipeline to output directory
output_1000/model-last

Results for 1000 sentences:
ℹ Using CPU

================================== Results ==================================

TOK     100.00
NER P   98.50 
NER R   98.25 
NER F   98.37 
SPEED   23690 


=============================== NER (per type) ===============================

                    P       R       F
VILLE_ORIGINE   98.00   98.00   98.00
VILLE_ARRIVEE   98.99   98.50   98.75


--- Finished testing with 1000 sentences ---

--- Testing with 5000 sentences ---
Data prepared with 5000 sentences.
Train: 4000 examples
Dev: 1000 examples
⚠ To generate a more effective transformer-based config (GPU-only),
install the spacy-transformers package and re-run this command. The config
generated now does not use transformers.
ℹ Generated config template specific for your use case
- Language: fr
- Pipeline: ner
- Optimize for: efficiency
- Hardware: CPU
- Transformer: None
✔ Auto-filled config with all values
✔ Saved config
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
✔ Created output directory: output_5000
ℹ Saving to output directory: output_5000
ℹ Using CPU

=========================== Initializing pipeline ===========================
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['tok2vec', 'ner']
ℹ Initial learn rate: 0.001
E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  ------------  --------  ------  ------  ------  ------
  0       0          0.00     61.20    0.00    0.00    0.00    0.00
  0     200        178.22   2976.21   95.18   95.56   94.80    0.95
  1     400        225.55    437.26   97.34   97.59   97.10    0.97
  2     600        254.97    284.70   97.93   97.66   98.20    0.98
  3     800        283.65    177.94   98.37   98.50   98.25    0.98
  4    1000        276.06    137.75   99.00   99.00   99.00    0.99
  6    1200        493.95    117.46   98.65   98.60   98.70    0.99
  8    1400        238.22     69.89   99.15   99.10   99.20    0.99
 11    1600        894.04    187.02   99.02   99.20   98.85    0.99
 14    1800        197.16     45.99   99.22   99.30   99.15    0.99
 18    2000          0.48      0.07   99.22   99.30   99.15    0.99
 22    2200        120.76     20.85   99.00   99.25   98.75    0.99
 28    2400        130.07     24.22   99.05   99.05   99.05    0.99
 33    2600        278.97     35.59   98.68   98.46   98.90    0.99
 39    2800       1121.17    144.32   99.10   99.25   98.95    0.99
 45    3000        281.16     40.20   98.70   98.90   98.50    0.99
 51    3200         61.64     12.19   98.70   98.80   98.60    0.99
 56    3400        276.51     37.48   99.30   99.35   99.25    0.99
 62    3600       5129.17    490.32   98.92   99.05   98.80    0.99
 68    3800        417.17     62.06   99.08   99.00   99.15    0.99
 73    4000         39.03      5.21   99.30   99.30   99.30    0.99
 79    4200         35.96      3.64   99.00   99.10   98.90    0.99
 85    4400          0.07      0.01   98.65   98.89   98.40    0.99
 91    4600         95.55     10.43   98.77   98.95   98.60    0.99
 96    4800        107.47      7.38   99.05   99.20   98.90    0.99
102    5000         33.85      4.01   99.22   99.25   99.20    0.99
108    5200        119.37     12.17   99.00   98.95   99.05    0.99
113    5400       5240.46    416.48   97.81   98.33   97.30    0.98
119    5600        467.66     68.87   98.70   98.80   98.60    0.99
✔ Saved pipeline to output directory
output_5000/model-last

Results for 5000 sentences:
ℹ Using CPU

================================== Results ==================================

TOK     100.00
NER P   99.30 
NER R   99.30 
NER F   99.30 
SPEED   24597 


=============================== NER (per type) ===============================

                    P       R       F
VILLE_ORIGINE   99.30   99.30   99.30
VILLE_ARRIVEE   99.30   99.30   99.30


--- Finished testing with 5000 sentences ---

--- Testing with 10000 sentences ---
Data prepared with 10000 sentences.
Train: 8000 examples
Dev: 2000 examples
⚠ To generate a more effective transformer-based config (GPU-only),
install the spacy-transformers package and re-run this command. The config
generated now does not use transformers.
ℹ Generated config template specific for your use case
- Language: fr
- Pipeline: ner
- Optimize for: efficiency
- Hardware: CPU
- Transformer: None
✔ Auto-filled config with all values
✔ Saved config
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
✔ Created output directory: output_10000
ℹ Saving to output directory: output_10000
ℹ Using CPU

=========================== Initializing pipeline ===========================
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['tok2vec', 'ner']
ℹ Initial learn rate: 0.001
E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  ------------  --------  ------  ------  ------  ------
  0       0          0.00     59.60    0.00    0.00    0.00    0.00
  0     200        174.34   2869.75   97.14   97.15   97.12    0.97
  0     400        208.19    422.35   97.52   97.62   97.42    0.98
  1     600        220.16    349.65   98.66   98.63   98.70    0.99
  1     800        411.38    326.62   98.79   98.85   98.72    0.99
  2    1000        576.58    295.39   98.90   98.88   98.92    0.99
  3    1200        356.22    200.74   99.51   99.50   99.52    1.00
  4    1400        352.31    117.57   99.32   99.35   99.30    0.99
  5    1600        656.38    161.59   99.28   99.23   99.32    0.99
  7    1800        269.46     82.41   99.46   99.45   99.47    0.99
  9    2000        738.60     96.01   99.42   99.45   99.40    0.99
 11    2200        234.99     61.66   99.39   99.42   99.35    0.99
 14    2400        246.87     49.71   99.38   99.35   99.40    0.99
 17    2600       1005.94    108.12   99.40   99.45   99.35    0.99
 19    2800       1428.90     70.54   99.29   99.25   99.32    0.99
✔ Saved pipeline to output directory
output_10000/model-last

Results for 10000 sentences:
ℹ Using CPU

================================== Results ==================================

TOK     100.00
NER P   99.50 
NER R   99.52 
NER F   99.51 
SPEED   23464 


=============================== NER (per type) ===============================

                    P       R       F
VILLE_ORIGINE   99.45   99.55   99.50
VILLE_ARRIVEE   99.55   99.50   99.52


--- Finished testing with 10000 sentences ---

--- Testing with 20000 sentences ---
Data prepared with 20000 sentences.
Train: 16000 examples
Dev: 4000 examples
⚠ To generate a more effective transformer-based config (GPU-only),
install the spacy-transformers package and re-run this command. The config
generated now does not use transformers.
ℹ Generated config template specific for your use case
- Language: fr
- Pipeline: ner
- Optimize for: efficiency
- Hardware: CPU
- Transformer: None
✔ Auto-filled config with all values
✔ Saved config
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
✔ Created output directory: output_20000
ℹ Saving to output directory: output_20000
ℹ Using CPU

=========================== Initializing pipeline ===========================
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['tok2vec', 'ner']
ℹ Initial learn rate: 0.001
E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  ------------  --------  ------  ------  ------  ------
  0       0          0.00     55.60    0.00    0.00    0.00    0.00
  0     200        237.98   2963.46   95.21   95.21   95.20    0.95
  0     400        223.49    462.62   98.32   98.49   98.14    0.98
  0     600        289.66    384.34   98.07   98.11   98.02    0.98
  0     800        370.24    357.58   98.90   98.91   98.89    0.99
  1    1000        282.80    232.72   98.91   98.83   99.00    0.99
  1    1200        697.56    282.38   98.75   98.71   98.79    0.99
  2    1400        483.90    223.39   99.38   99.41   99.35    0.99
  2    1600        638.42    204.00   99.26   99.30   99.21    0.99
  3    1800        437.72    173.87   99.59   99.60   99.59    1.00
  4    2000       1067.46    171.97   99.50   99.50   99.50    0.99
  5    2200       1129.30    177.61   99.41   99.50   99.32    0.99
  7    2400        462.22     98.17   99.67   99.66   99.69    1.00
  8    2600       1034.70    100.01   99.59   99.61   99.56    1.00
  9    2800        978.64     82.69   99.70   99.70   99.70    1.00
 11    3000        109.31     20.26   99.62   99.67   99.56    1.00
 12    3200        108.33     18.91   99.27   99.40   99.14    0.99
 14    3400       1205.66     85.76   99.46   99.56   99.35    0.99
 15    3600       2033.07     98.13   99.46   99.49   99.42    0.99
 16    3800        266.04     40.44   99.66   99.69   99.62    1.00
 18    4000        143.88     18.27   99.54   99.54   99.55    1.00
 19    4200        573.94     21.90   99.59   99.59   99.60    1.00
 21    4400        779.60     76.43   99.59   99.61   99.56    1.00
✔ Saved pipeline to output directory
output_20000/model-last

Results for 20000 sentences:
ℹ Using CPU

================================== Results ==================================

TOK     100.00
NER P   99.70 
NER R   99.70 
NER F   99.70 
SPEED   27201 


=============================== NER (per type) ===============================

                    P       R       F
VILLE_ARRIVEE   99.68   99.75   99.71
VILLE_ORIGINE   99.72   99.65   99.69


--- Finished testing with 20000 sentences ---
